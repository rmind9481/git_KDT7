{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [동적 모델 설계 구현]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\t사용 모듈 : nn.ModuleList\n",
    "-\t특징 : 일반 list 로는 pytorch 에서 Layer 인식 안된 ==> 대안 : ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 모델 설계\n",
    "# -\t입력층\n",
    "# - 은닉층  <=== 유동적 0개 ~ N 개 : 모델 인스턴스 생성 시 매개 변수 전달인자\n",
    "# - 출력층 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\t\t\t\t\t# 데이터셋 관련\n",
    "\n",
    "from torchmetrics.classification import *\t\t\t\t\t\t# 모델성능 지표 관련\n",
    "from torchinfo import summary\t\t\t\t\t\t\t\t\t# 모델구조 및 정보 관련\n",
    "\n",
    "from sklearn.model_selection import train_test_split\t\t\t# 학습용 & 테스트용 데이터셋 분리\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\t# 연속형 피쳐 스케일링\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\t# 범주형 피쳐 타겟 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 모델 클래스 정의 (2) - 은닉층 개수 및 뉴런 개수 동적인 모델 -------------------------\n",
    "# \n",
    "class MyModel(nn.Module):\n",
    "\n",
    "\tdef __init__(self, in_in, out_out, h_in, h_cnt) :\n",
    "\t\t# 부모 클래스\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t# 자식 클래스 의 인스턴스 속성 설정\n",
    "\t\tself.input_layer = nn.Linear(in_in, h_in)\n",
    "\t\tself.h1_layer = nn.ModuleList([nn.Linear(h_in,h_in) for _ in range(h_cnt)])\n",
    "\t\tself.output_layer = nn.Linear(h_in, out_out)\n",
    "\n",
    "\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\n",
    "\t\ty = F.relu(self.input_layer(x))\n",
    "\n",
    "\t\tfor linear in self.h1_layer:\n",
    "\t\t\ty = F.relu(linear(y))\n",
    "\n",
    "\t\t\n",
    "\t\treturn self.output_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1037]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스터스 생성\n",
    "# in_in = 3\n",
    "# out_out = 1\n",
    "# hd_in = 5\n",
    "# hd_cut =1\n",
    "m1 = MyModel(3,1,50,1)\n",
    "\n",
    "m1(torch.FloatTensor([[1,2,3]]))\t\t# 샘플수 , 피쳐수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [100, 1]                  --\n",
       "├─Linear: 1-1                            [100, 50]                 200\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─Linear: 2-1                       [100, 50]                 2,550\n",
       "├─Linear: 1-3                            [100, 1]                  51\n",
       "==========================================================================================\n",
       "Total params: 2,801\n",
       "Trainable params: 2,801\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.08\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(m1, input_size=(100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (input_layer): Linear(in_features=3, out_features=10, bias=True)\n",
       "  (h1_layer): ModuleList(\n",
       "    (0-9): 10 x Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = MyModel(3,3,10,10)\n",
    "\n",
    "m2(torch.FloatTensor([[1,2,3]]))\t\t# 샘플수 , 피쳐수\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층 개수 및 뉴런 개수 동적 모델(2) > 은닉층 개수와 뉴런 개수 동적인 모델 \n",
    "# in_in : 입력층의 입력 in_out : 입력층의 출력 / 다음층의 입력\n",
    "# out_out : 출력층의 출력 h_outs = [] : 은닉층의 출력 리스트\n",
    "class DynamicModel(nn.Module):\n",
    "   def __init__(self, in_in, in_out ,out_out, h_outs = []) :\n",
    "      # 부모 클래스 생성\n",
    "      super().__init__()\n",
    "   \n",
    "   # 자식클래스의 인스턴스 속성 설정\n",
    "      self.input_layer = nn.Linear(in_in, in_out)\n",
    "\n",
    "      # 은닉층 여러개 생성\n",
    "      self.h1_layer = nn.ModuleList()\n",
    "      for idx in range(len(h_outs)):\n",
    "         h_in = h_outs[idx-1] if idx else in_out\n",
    "         h_out = h_outs[idx]\n",
    "         self.h1_layer.append(nn.Linear(h_in, h_out))\n",
    "      \n",
    "      # 출력층 생성\n",
    "      self.output_layer = nn.Linear(h_outs[-1] if len(h_outs) else in_out, out_out)\n",
    "\n",
    "   \n",
    "   # 순전파 학습 메서드\n",
    "   def forward(self,x):\n",
    "\n",
    "      y = F.relu(self.input_layer(x))\n",
    "\n",
    "      for linear in self.h1_layer:\n",
    "         y = F.relu(linear(y))\n",
    "\n",
    "      return self.output_layer(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 동적 모델 클래스 정의 (2) - 은닉층 개수 및 뉴런 개수 동적인 모델 -------------------------\n",
    "# # in_in : 입력층의 입력  in_out \t\t: 입력층의 출력/ 다음층의 입력\n",
    "# # out_out : 출력층의 출력 h_outs = []\t: 은닉층의 출력리스트\n",
    "\n",
    "# class DyanmicMyModel(nn.Module):\n",
    "\n",
    "# \tdef __init__(self, in_in, in_out,out_out, h_outs=[]) :\n",
    "# \t\t# 부모 클래스\n",
    "# \t\tsuper().__init__()\n",
    "\n",
    "# \t\t# 자식 클래스 의 인스턴스 속성 설정\n",
    "# \t\tself.input_layer = nn.Linear(in_in, h_in)\n",
    "\t\t\n",
    "# \t\t# 은닉층 여러개 생성\n",
    "# \t\tself.h1_layer = nn.ModuleList()\n",
    "\t\t\n",
    "# \t\tfor idx in range(len(h_outs)):\n",
    "# \t\t\th_in = h_outs[idx-1] if idx else in_out\n",
    "# \t\t\th_out = h_outs[idx]\n",
    "# \t\t\tself.h1_layer.append( nn.Linear(h_in, h_out))\n",
    "\n",
    "\t\t\n",
    "# \t\t# 출력층 생성\n",
    "# \t\tself.output_layer = nn.Linear(h_outs[-1] if len(h_outs) else in_out, out_out)\n",
    "\n",
    "\n",
    "# \tdef forward(self,x):\n",
    "\n",
    "# \t\ty = F.relu(self.input_layer(x))\n",
    "\n",
    "# \t\tfor linear in self.h1_layer:\n",
    "# \t\t\ty = F.relu(linear(y))\n",
    "\n",
    "\t\t\n",
    "# \t\treturn self.output_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DynamicModel                             [100, 1]                  --\n",
       "├─Linear: 1-1                            [100, 5]                  20\n",
       "├─Linear: 1-2                            [100, 1]                  6\n",
       "==========================================================================================\n",
       "Total params: 26\n",
       "Trainable params: 26\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스터스 생성\n",
    "# in_in : 입력층의 입력   in_out : 입력층의 출력/ 다음층의 입력\n",
    "# out_out : 출력층의 출력 h_outs =[] : 은닉층의 출력  리스트\n",
    "m1 = DynamicModel(3,5,1)\n",
    "m1(torch.FloatTensor([[1,2,3]]))\t\t# 샘플수 , 피쳐수\n",
    "\n",
    "summary(m1, input_size=(100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DynamicModel                             [100, 3]                  --\n",
       "├─Linear: 1-1                            [100, 10]                 40\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─Linear: 2-1                       [100, 7]                  77\n",
       "│    └─Linear: 2-2                       [100, 5]                  40\n",
       "├─Linear: 1-3                            [100, 3]                  18\n",
       "==========================================================================================\n",
       "Total params: 175\n",
       "Trainable params: 175\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.02\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.02\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.02\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스터스 생성\n",
    "# in_in : 입력층의 입력   in_out : 입력층의 출력/ 다음층의 입력\n",
    "# out_out : 출력층의 출력 h_outs =[] : 은닉층의 출력  리스트\n",
    "m1 = DynamicModel(3,10,3,[7,5])\n",
    "m1(torch.FloatTensor([[1,2,3]]))\t\t# 샘플수 , 피쳐수\n",
    "\n",
    "summary(m1, input_size=(100,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
