{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [ DL CUSTOM MODEL ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 모듈로딩 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                        ## 텐서 및 기본 함수들 관련 모듈\n",
    "import torch.nn as nn               ## 인공신경망 관련 층과 알고리즘 클래스 모듈\n",
    "import torch.nn.functional as F     ## 인공신경망 관련 함수들 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 모델 설계 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]  환경 상황 예측 모델  \n",
    "- 피쳐 : 3개 \n",
    "- 타겟 : 연속형 1개\n",
    "- 학습 : 지도학습 + 회귀 \n",
    "- 알고리즘 : 인공신경망 계열 - DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 클래스 설계 ----------------------------------------------------------------------\n",
    "## 회귀용 커스텀 모델 \n",
    "## 클래스이름 :  CustomRegressionModel\n",
    "## 부모클래스 :  nn.Module\n",
    "## 모델층구성    입력신호/피쳐수       출력신호수/퍼셉트론수          활성화함수\n",
    "## - 입력층  :       in_in                in_out                  ReLU\n",
    "##                   _____________________|\n",
    "##                  | \n",
    "##                  ▼\n",
    "## - 은닉층  :      in_out                h1_out                  ReLU \n",
    "##                   _____________________|\n",
    "##                  | \n",
    "##                  ▼\n",
    "## - 은닉층  :      h1_out                h2_out                  ReLU\n",
    "##                   _____________________|\n",
    "##                  | \n",
    "##                  ▼\n",
    "## - 출력층  :     h2_out                 out_out                   X \n",
    "## - -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRegressionModel(nn.Module):\n",
    "    ## 모델 층 구성 관련 초기화\n",
    "    def __init__(self, in_in, in_out, h1_out, h2_out, out_out):\n",
    "        super().__init__()\n",
    "        self.in_layer  = nn.Linear(in_in,  in_out)\n",
    "        self.h_layer1  = nn.Linear(in_out, h1_out)\n",
    "        self.h_layer2  = nn.Linear(h1_out, h2_out)\n",
    "        self.out_layer = nn.Linear(h2_out, out_out)\n",
    "\n",
    "    ## 학습 즉, 순방향 학습 진행 메서드 forward : 필수 오버라이딩 메서드 \n",
    "    ## 매개변수 data : 학습용 데이터 전달\n",
    "    def forward(self, data):\n",
    "        # 입력 => 입력층 학습\n",
    "        out=self.in_layer(data)  ## 출력 f1*w11+f2*w12+f3*W13+b1, ..., f1*w501+f2*w502+f3*W503+b50\n",
    "        out=F.relu(out)\n",
    "\n",
    "        # 은닉층 \n",
    "        out=self.h_layer1(out)  ## 출력 f1*w11+....+f50*W150+b1, ..., f1*w301+...+f50*W3050+b30\n",
    "        out=F.relu(out)\n",
    "\n",
    "        # 은닉층 \n",
    "        out=self.h_layer2(out)  ## 출력 f1*w11+....+f30*W130+b1, ..., f1*w101+...+f30*W1030+b10\n",
    "        out=F.relu(out)\n",
    "\n",
    "        # 출력층\n",
    "        out=self.out_layer(out)  ## 출력 f1*w11+....+f10*W110+b1\n",
    "\n",
    "        return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4584]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모델 설계 체크 \n",
    "model = MyCustomModel()\n",
    "model(torch.FloatTensor([[22,33,44]]))  # (1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[in_layer.weight-torch.Size([50, 3])]===================\n",
      "Parameter containing:\n",
      "tensor([[-0.0667,  0.0607,  0.2364],\n",
      "        [ 0.1233, -0.1247, -0.1333],\n",
      "        [ 0.5054,  0.0020, -0.5261],\n",
      "        [-0.4800,  0.5768,  0.3839],\n",
      "        [-0.0262,  0.1622, -0.3054],\n",
      "        [ 0.0497, -0.3429, -0.0969],\n",
      "        [-0.4499,  0.4305, -0.5295],\n",
      "        [ 0.3241, -0.1629, -0.0916],\n",
      "        [ 0.3487,  0.3106,  0.3828],\n",
      "        [ 0.0946, -0.3812,  0.2936],\n",
      "        [ 0.2678,  0.0833, -0.3720],\n",
      "        [ 0.5546, -0.3717, -0.1074],\n",
      "        [-0.3104,  0.1647, -0.4484],\n",
      "        [ 0.4710, -0.5562,  0.5709],\n",
      "        [-0.5624, -0.5365, -0.0464],\n",
      "        [-0.3280, -0.3476,  0.3593],\n",
      "        [-0.4241, -0.2115, -0.4413],\n",
      "        [ 0.5580, -0.3823, -0.5667],\n",
      "        [-0.0739, -0.1248,  0.5425],\n",
      "        [-0.5026,  0.1532, -0.0587],\n",
      "        [-0.4269,  0.3186, -0.5370],\n",
      "        [ 0.5219, -0.0402,  0.4023],\n",
      "        [ 0.5487,  0.2996,  0.1807],\n",
      "        [ 0.4356,  0.0673, -0.1241],\n",
      "        [ 0.4870, -0.2060, -0.0293],\n",
      "        [ 0.5449, -0.2147, -0.5357],\n",
      "        [-0.3507,  0.2232,  0.5193],\n",
      "        [-0.0140, -0.2473, -0.1874],\n",
      "        [ 0.2867, -0.3064, -0.0580],\n",
      "        [ 0.0030, -0.4742, -0.4143],\n",
      "        [ 0.1379,  0.0286,  0.0503],\n",
      "        [-0.1345,  0.4139, -0.5378],\n",
      "        [ 0.0995,  0.0454, -0.1473],\n",
      "        [-0.4238,  0.3051,  0.2786],\n",
      "        [ 0.3876, -0.4776,  0.0123],\n",
      "        [ 0.4610,  0.5689,  0.2074],\n",
      "        [-0.2678,  0.5183,  0.3939],\n",
      "        [-0.0886, -0.2446,  0.4621],\n",
      "        [ 0.3571,  0.2186, -0.0033],\n",
      "        [ 0.2088,  0.1845,  0.1472],\n",
      "        [ 0.2494,  0.1916,  0.5750],\n",
      "        [-0.3909, -0.0572,  0.4926],\n",
      "        [ 0.2403,  0.1816, -0.3163],\n",
      "        [ 0.0334, -0.4459,  0.2093],\n",
      "        [-0.0770, -0.4865, -0.2840],\n",
      "        [-0.5685,  0.3083, -0.5248],\n",
      "        [ 0.2844,  0.3218, -0.1009],\n",
      "        [ 0.4695,  0.5270, -0.3477],\n",
      "        [-0.4899, -0.5709, -0.5416],\n",
      "        [ 0.5126,  0.3055, -0.2454]], requires_grad=True)\n",
      "\n",
      "[in_layer.bias-torch.Size([50])]===================\n",
      "Parameter containing:\n",
      "tensor([ 0.3282, -0.1740,  0.4465, -0.0300,  0.4300,  0.0992, -0.1544, -0.4166,\n",
      "         0.4482,  0.4874,  0.0749,  0.0814, -0.2357,  0.2782,  0.4292, -0.3102,\n",
      "         0.4479,  0.2952,  0.5198, -0.4531,  0.0316, -0.2626, -0.2222, -0.1001,\n",
      "         0.5560, -0.1677, -0.1134,  0.4371,  0.5748,  0.0366, -0.3039, -0.4892,\n",
      "         0.0907, -0.2904, -0.3357, -0.3915, -0.0189,  0.3827,  0.3075, -0.5004,\n",
      "         0.5516, -0.1840, -0.2269, -0.5394, -0.3607,  0.5772,  0.2617, -0.5420,\n",
      "         0.0762, -0.3633], requires_grad=True)\n",
      "\n",
      "[h_layer1.weight-torch.Size([30, 50])]===================\n",
      "Parameter containing:\n",
      "tensor([[ 0.0815, -0.0889,  0.0267,  ...,  0.0329, -0.0149,  0.0379],\n",
      "        [-0.1194, -0.0417,  0.1268,  ..., -0.0937, -0.0824, -0.0598],\n",
      "        [-0.0258, -0.0179, -0.0470,  ..., -0.1304,  0.0418, -0.1269],\n",
      "        ...,\n",
      "        [-0.0279, -0.0653,  0.1100,  ..., -0.1257, -0.0649, -0.0936],\n",
      "        [-0.0031, -0.1313,  0.0087,  ...,  0.0542, -0.0578,  0.0158],\n",
      "        [ 0.0354, -0.0297, -0.0023,  ..., -0.1250, -0.0975,  0.0379]],\n",
      "       requires_grad=True)\n",
      "\n",
      "[h_layer1.bias-torch.Size([30])]===================\n",
      "Parameter containing:\n",
      "tensor([-0.0927, -0.0919,  0.0463,  0.0383,  0.1169,  0.1173, -0.0070,  0.0020,\n",
      "        -0.0963, -0.0851, -0.0835,  0.0276,  0.0018,  0.0027, -0.1211, -0.0840,\n",
      "        -0.0532,  0.0881, -0.1233, -0.1216, -0.0196, -0.0288, -0.0983,  0.0425,\n",
      "        -0.0932, -0.0842,  0.0814, -0.0202,  0.0489,  0.0162],\n",
      "       requires_grad=True)\n",
      "\n",
      "[h_layer2.weight-torch.Size([10, 30])]===================\n",
      "Parameter containing:\n",
      "tensor([[ 0.1167,  0.1681, -0.0536,  0.0788, -0.0550, -0.1406, -0.0926,  0.1026,\n",
      "         -0.1789, -0.1473,  0.0265,  0.1153,  0.0340, -0.1618, -0.0544, -0.0856,\n",
      "         -0.0028,  0.0761,  0.0442, -0.0673,  0.1180,  0.1800,  0.1028, -0.0364,\n",
      "          0.1782,  0.0156,  0.0312, -0.0173,  0.0954, -0.0673],\n",
      "        [ 0.1555, -0.0539,  0.1734,  0.1480,  0.1404, -0.0072,  0.0259,  0.1593,\n",
      "         -0.1400, -0.0258,  0.1224, -0.1750,  0.1420, -0.1536,  0.1195, -0.1469,\n",
      "          0.0732,  0.1632, -0.0102,  0.0166,  0.0752,  0.0325,  0.0244,  0.0795,\n",
      "         -0.1784,  0.1785,  0.0489, -0.0971, -0.0155,  0.0967],\n",
      "        [ 0.1031,  0.0618, -0.0720,  0.1752, -0.0779,  0.0438,  0.0561,  0.0843,\n",
      "          0.1688, -0.1292,  0.1532,  0.0045,  0.1569,  0.0894, -0.0161, -0.0641,\n",
      "          0.0855,  0.1115, -0.0945,  0.0943, -0.1360,  0.0914, -0.1631,  0.0619,\n",
      "         -0.0931, -0.0018, -0.1359, -0.0438, -0.1395, -0.1133],\n",
      "        [ 0.1062,  0.0115,  0.1138,  0.0314,  0.1356, -0.1569,  0.0627, -0.0786,\n",
      "          0.0981,  0.1197, -0.1803, -0.0356, -0.0817, -0.0043,  0.1415, -0.1246,\n",
      "         -0.1645,  0.0421, -0.0513,  0.0551, -0.1007,  0.1432,  0.0170, -0.0153,\n",
      "          0.0591, -0.0709,  0.1463,  0.1384, -0.1606,  0.0041],\n",
      "        [-0.0969, -0.0041, -0.1105,  0.0247,  0.0492, -0.0697, -0.0202,  0.1527,\n",
      "         -0.1497, -0.0844, -0.1057,  0.0202, -0.1080, -0.0700, -0.1304,  0.0653,\n",
      "          0.1619, -0.1340, -0.1088, -0.0020,  0.1257,  0.0994,  0.1436, -0.1180,\n",
      "          0.0636, -0.1617,  0.1076, -0.1040,  0.0586,  0.0033],\n",
      "        [ 0.1158,  0.0723,  0.0727, -0.0845,  0.1807,  0.0549, -0.0600, -0.1042,\n",
      "         -0.1076, -0.0434, -0.1124, -0.0250, -0.1160,  0.0230, -0.0154,  0.0469,\n",
      "          0.0435, -0.0542,  0.0423, -0.0551, -0.0979,  0.0570,  0.0106, -0.0987,\n",
      "          0.0934, -0.0162, -0.1214,  0.1613, -0.1090, -0.1354],\n",
      "        [-0.1612, -0.0802, -0.1181, -0.1161, -0.0425,  0.1750, -0.1473,  0.1469,\n",
      "         -0.0302,  0.1518,  0.1250,  0.0353,  0.1679,  0.0324,  0.0465,  0.1270,\n",
      "         -0.0741,  0.1699,  0.1341,  0.1446, -0.1092, -0.0380, -0.0255, -0.1268,\n",
      "          0.0391,  0.0263,  0.0852,  0.1377,  0.1095, -0.0906],\n",
      "        [ 0.1490, -0.1697, -0.0032,  0.1633, -0.1500, -0.0622,  0.0345,  0.1360,\n",
      "         -0.1825, -0.0371, -0.0046, -0.0562, -0.0555, -0.1732,  0.1681,  0.1291,\n",
      "          0.1484,  0.1631, -0.1767,  0.1721, -0.1456,  0.0661, -0.1726, -0.1710,\n",
      "         -0.0774, -0.1607, -0.0842, -0.0810,  0.0887, -0.0847],\n",
      "        [-0.0436,  0.0533,  0.0102,  0.1264,  0.0844,  0.0347, -0.1043, -0.0776,\n",
      "         -0.1336,  0.0770,  0.0893, -0.0360, -0.0113,  0.1115, -0.1321, -0.0416,\n",
      "          0.1393,  0.1282,  0.0156, -0.0657, -0.0853, -0.1197,  0.1724, -0.0473,\n",
      "          0.1776,  0.1308, -0.0258,  0.0215,  0.1099,  0.0692],\n",
      "        [-0.1354,  0.0835, -0.0062, -0.0515, -0.1591,  0.1741,  0.0982, -0.0324,\n",
      "          0.0628, -0.0942,  0.1313, -0.1162,  0.1822, -0.1457,  0.0434, -0.0237,\n",
      "          0.1590,  0.1368, -0.1148, -0.1184,  0.1361, -0.1037, -0.1579,  0.1281,\n",
      "          0.0782,  0.0715, -0.1193, -0.0475, -0.1754, -0.1631]],\n",
      "       requires_grad=True)\n",
      "\n",
      "[h_layer2.bias-torch.Size([10])]===================\n",
      "Parameter containing:\n",
      "tensor([ 0.0842,  0.1179, -0.1165,  0.1338, -0.1533, -0.1039,  0.1708,  0.0268,\n",
      "        -0.0681,  0.0087], requires_grad=True)\n",
      "\n",
      "[out_layer.weight-torch.Size([1, 10])]===================\n",
      "Parameter containing:\n",
      "tensor([[ 0.2799,  0.1631, -0.0955, -0.3028, -0.0159, -0.1729, -0.0657,  0.1994,\n",
      "         -0.2062, -0.2905]], requires_grad=True)\n",
      "\n",
      "[out_layer.bias-torch.Size([1])]===================\n",
      "Parameter containing:\n",
      "tensor([0.1004], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## 모델 층별 파라미터 즉, W와 b \n",
    "for name, param in model.named_parameters():\n",
    "    print(f'\\n[{name}-{param.shape}]===================')\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2]  이미지 분류 모델  \n",
    "- 이미지 크기 : 30 * 30 , 흑백이미지 \n",
    "- 피쳐 : 900 (30*30*1)\n",
    "- 타겟 : 자동차와 나무 분류\n",
    "- 학습 : 지도학습 - 분류 => 이진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 클래스 설계 ----------------------------------------------------------------------\n",
    "## 클래스이름 :  CutomImgModel\n",
    "## 부모클래스 :  nn.Module\n",
    "## 모델층구성    입력신호/피쳐수       출력신호수/퍼셉트론수      활성화함수\n",
    "## - 입력층  :       900                   250              ReLU\n",
    "##                   _____________________|\n",
    "##                  | \n",
    "##                  ▼\n",
    "## - 은닉층  :     250                    150               ReLU \n",
    "##                   _____________________|\n",
    "##                  | \n",
    "##                  ▼\n",
    "## - 은닉층  :     150                    70                 ReLU\n",
    "##                   _____________________|\n",
    "##                  | \n",
    "##                  ▼\n",
    "## - 출력층  :      70                     1                 simgoid \n",
    "## - -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 분류 모델 클래스 설계 \n",
    "class CustomImgModel(nn.Module):\n",
    "    ## 모델 설계 초기화\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_layer  = nn.Linear(900, 250)\n",
    "        self.h_layer1  = nn.Linear(250, 150)\n",
    "        self.h_layer2  = nn.Linear(150, 100)\n",
    "        self.h_layer3  = nn.Linear(100, 50)\n",
    "        self.out_layer = nn.Linear(50,  1)\n",
    "\n",
    "    ## 학습 즉, 순방향 학습 진행 메서드 forward : 필수 오버라이딩 메서드 \n",
    "    ## 매개변수 data : 학습용 데이터 전달\n",
    "    def forward(self, data):\n",
    "        # 입력 => 입력층 학습\n",
    "        out=self.in_layer(data)  ## 출력 f1*w11+f2*w12+f3*W13+b1, ..., f1*w501+f2*w502+f3*W503+b50\n",
    "        out=F.relu(out)\n",
    "\n",
    "        # 은닉층 \n",
    "        out=self.h_layer1(out)  ## 출력 f1*w11+....+f50*W150+b1, ..., f1*w301+...+f50*W3050+b30\n",
    "        out=F.relu(out)\n",
    "\n",
    "        # 은닉층 \n",
    "        out=self.h_layer2(out)  ## 출력 f1*w11+....+f30*W130+b1, ..., f1*w101+...+f30*W1030+b10\n",
    "        out=F.relu(out)\n",
    "\n",
    "        # 은닉층 \n",
    "        out=self.h_layer3(out)  ## 출력 f1*w11+....+f30*W130+b1, ..., f1*w101+...+f30*W1030+b10\n",
    "        out=F.relu(out)\n",
    "\n",
    "        # 출력층\n",
    "        out=self.out_layer(out)  ## 출력 f1*w11+....+f10*W110+b1\n",
    "        out=F.sigmoid(out)       ## 이진분류 AF \n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 분류 모델 클래스 설계 \n",
    "class CustomImgModel(nn.Module):\n",
    "    ## 모델 설계 초기화\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(900, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    ## 학습 즉, 순방향 학습 진행 메서드 forward : 필수 오버라이딩 메서드 \n",
    "    ## 매개변수 data : 학습용 데이터 전달\n",
    "    def forward(self, data):\n",
    "        return self.layers(data) \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
